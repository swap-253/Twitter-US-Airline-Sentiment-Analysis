{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airline Sentiment Analysis Using LSTMs with pickle file.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9zB1sV_Q-mD"
      },
      "source": [
        "#creating a directory\n",
        "!mkdir ~/.kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv875k2SQ-rp"
      },
      "source": [
        "#using credentials to open kaggle dataset\n",
        "import json\n",
        "token = {\"username\":\"nishurocks23\",\"key\":\"26c5d88e7d80c0b16e9c5c7ac10f1c60\"}\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kNSXWDWQ-wL",
        "outputId": "6483793e-8e15-4914-ebc0-badab55fdaba"
      },
      "source": [
        "!cp /root/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: '/root/.kaggle/kaggle.json' and '/root/.kaggle/kaggle.json' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNKMol8lQ-yu",
        "outputId": "7fb6f5fc-c36c-475f-ac43-d0b4abe6152c"
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP4XQ1YIQ-3W"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M66aTLViQ--2",
        "outputId": "26c07ab6-23cd-4a5d-cba6-2b3d2d409606"
      },
      "source": [
        "#downloading the zipped dataset folder on cloud\n",
        "!kaggle datasets download -d crowdflower/twitter-airline-sentiment -p /content"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading twitter-airline-sentiment.zip to /content\n",
            "\r  0% 0.00/2.55M [00:00<?, ?B/s]\n",
            "\r100% 2.55M/2.55M [00:00<00:00, 81.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efz7GmrwQ_Bn",
        "outputId": "6f00ece1-ff1f-4d65-e282-c4d8b57903c1"
      },
      "source": [
        "#unzipping the folder\n",
        "!unzip \\*.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  twitter-airline-sentiment.zip\n",
            "  inflating: Tweets.csv              \n",
            "  inflating: database.sqlite         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1V7qfmQXs8g",
        "outputId": "838e376e-3c8d-4145-e561-e4622b3d8e63"
      },
      "source": [
        "!pip install keras-tuner"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=ee78a0b430bfec54f606cfd5b576fbf9e08348152959bc9267efcfd6df0c3d4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=c3120f2b8503a08e72d07a241dc290c55319ac55fe183c76698e8e08aadb6019\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INsvANBUQ_Nn"
      },
      "source": [
        "\n",
        "#importing libraries for model evaluation and algorithms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import collections\n",
        "import nltk\n",
        "from sklearn import preprocessing\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "# Packages for data preparation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#dl libraraies\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization,Reshape,Dot,Concatenate,Add,Lambda\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import cv2\n",
        "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# specifically for deeplearning.\n",
        "from tensorflow.keras.layers import Dropout, Flatten,Activation,Input,Embedding\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "# Packages for modeling\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from kerastuner import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "DoU4sypRQ_Gj",
        "outputId": "f978d14b-7ba3-4d40-ce93-75637866a64e"
      },
      "source": [
        "#reading the dataframe\n",
        "df=pd.read_csv('Tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGb7zeFpwSc4",
        "outputId": "0168e68c-fc4d-473d-d54f-16977e85be3f"
      },
      "source": [
        "#removing the neutral sentiments considering that positive and negative sentiments matter more \n",
        "df=df[df['airline_sentiment']!='neutral']\n",
        "#now since neutral elements are deleted so I need to reset the indices\n",
        "df.reset_index(inplace=True,drop=True)\n",
        "#positive sentiments to 1 and negative to 0 \n",
        "def partition(x):\n",
        "    if x =='positive':\n",
        "        return 1\n",
        "    return 0\n",
        "actualSentiment = df['airline_sentiment']\n",
        "positiveNegative = actualSentiment.map(partition) \n",
        "df['Sentiment'] = positiveNegative\n",
        "df['Sentiment'].value_counts() "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    9178\n",
              "1    2363\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "Wfbovcn8wSfu",
        "outputId": "48383637-abe6-453e-b9a8-a83b2d1c2094"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570300767074181121</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>0.6842</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:33 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300616901320704</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.6745</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cjmcginnis</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:13:57 -0800</td>\n",
              "      <td>San Francisco CA</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id airline_sentiment  ...               user_timezone Sentiment\n",
              "0  570301130888122368          positive  ...  Pacific Time (US & Canada)         1\n",
              "1  570301031407624196          negative  ...  Pacific Time (US & Canada)         0\n",
              "2  570300817074462722          negative  ...  Pacific Time (US & Canada)         0\n",
              "3  570300767074181121          negative  ...  Pacific Time (US & Canada)         0\n",
              "4  570300616901320704          positive  ...  Pacific Time (US & Canada)         1\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoDUJUsPU0M3"
      },
      "source": [
        "#Setting parameters which will be used throughout\n",
        "num_words = 15000  # Parameter indicating the number of words we'll put in the dictionary\n",
        "val_size = 1000  # Size of the validation set\n",
        "epochs = 20  # Number of epochs we usually start to train with\n",
        "batch_size = 512  # Size of the batches used in the mini-batch gradient descent\n",
        "#Taking only two columns since it's a sentiment analysis"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jm0puHxWrnk",
        "outputId": "bbdded70-d311-4966-f6e9-0f10daba1fdc"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJTh5-ShU0P2"
      },
      "source": [
        "#tweets conssits of every document as an array of tokenized words which are later appended to docs \n",
        "tweets=[word_tokenize(tweet) for tweet in df['text']]\n",
        "docs=[]\n",
        "for j in range(0,len(tweets)):\n",
        "    docs.append(tweets[j])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-rXkF_1U0iE"
      },
      "source": [
        "#stops included both the stopwords and punctuations\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "stops = set(stopwords.words('english'))\n",
        "punctuations = list(string.punctuation)\n",
        "not_list = [\"n't\", \"not\", \"no\"]\n",
        "stops.update(punctuations)\n",
        "stops.update(not_list)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mxGxUnBWSv3"
      },
      "source": [
        "#to get the simple pos(part of speech) tag\n",
        "from nltk.corpus import wordnet\n",
        "def get_simple_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nO4zHxZWSzJ"
      },
      "source": [
        "#to get the pos tag for a word\n",
        "from nltk import pos_tag\n",
        "# now we are going to clean our data \n",
        "# we will remove stopwords and punctuations and lemmatize each document\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "def clean(words):\n",
        "    output=[]\n",
        "    for word in words:\n",
        "        if word.lower() not in stops or word.lower() in not_list:\n",
        "            pos=pos_tag(word)\n",
        "            clean_word=lemmatizer.lemmatize(word,pos=get_simple_pos(pos[0][1]))\n",
        "            output.append(clean_word.lower())\n",
        "    str1=\" \".join(output).encode('utf-8')        \n",
        "    return str1\n",
        "docs=[ clean(doc) for doc in docs]      "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEdvYfQdWS1m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "39d0a965-b7b2-4b86-c7a0-82fc12bcd08a"
      },
      "source": [
        "#docs was the cleaned lemmatized text which has been appended into the dataframe for further use\n",
        "df['CleanedText']=docs\n",
        "df['CleanedText']=df['CleanedText'].str.decode(\"utf-8\")\n",
        "def remove_mentions(input_text):\n",
        "        return re.sub(r'@\\w+', '', input_text)\n",
        "df.text = df.CleanedText.apply(remove_mentions)\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>CleanedText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>virginamerica plus 've added commercial experi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "      <td>1</td>\n",
              "      <td>virginamerica plus 've added commercial experi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>virginamerica 's really aggressive blast obnox...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "      <td>0</td>\n",
              "      <td>virginamerica 's really aggressive blast obnox...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>virginamerica 's really big bad thing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "      <td>0</td>\n",
              "      <td>virginamerica 's really big bad thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570300767074181121</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>0.6842</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>virginamerica seriously would pay 30 flight se...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:33 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "      <td>0</td>\n",
              "      <td>virginamerica seriously would pay 30 flight se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300616901320704</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.6745</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cjmcginnis</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>virginamerica yes nearly every time fly vx “ e...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:13:57 -0800</td>\n",
              "      <td>San Francisco CA</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "      <td>1</td>\n",
              "      <td>virginamerica yes nearly every time fly vx “ e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...                                        CleanedText\n",
              "0  570301130888122368  ...  virginamerica plus 've added commercial experi...\n",
              "1  570301031407624196  ...  virginamerica 's really aggressive blast obnox...\n",
              "2  570300817074462722  ...              virginamerica 's really big bad thing\n",
              "3  570300767074181121  ...  virginamerica seriously would pay 30 flight se...\n",
              "4  570300616901320704  ...  virginamerica yes nearly every time fly vx “ e...\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eywgfErHwShp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ff88c88a-69b0-4ca4-8bf4-bb1322e4a212"
      },
      "source": [
        "#taking only two columns in the dataframe\n",
        "df=df[['CleanedText','Sentiment']]\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CleanedText</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>virginamerica plus 've added commercial experi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>virginamerica 's really aggressive blast obnox...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>virginamerica 's really big bad thing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>virginamerica seriously would pay 30 flight se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>virginamerica yes nearly every time fly vx “ e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         CleanedText  Sentiment\n",
              "0  virginamerica plus 've added commercial experi...          1\n",
              "1  virginamerica 's really aggressive blast obnox...          0\n",
              "2              virginamerica 's really big bad thing          0\n",
              "3  virginamerica seriously would pay 30 flight se...          0\n",
              "4  virginamerica yes nearly every time fly vx “ e...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B9KW6XjAVa_"
      },
      "source": [
        "#taking variables to be used for train test split as X,y\n",
        "X,Y=df['CleanedText'].values,pd.get_dummies(df.Sentiment.values)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e57a2yp9AVfN",
        "outputId": "d89e109c-b42a-4d18-8630-a8f33bc1c9f9"
      },
      "source": [
        "#using tokenizers to create the tokens having no of words=15000(num_words)\n",
        "tk = Tokenizer(num_words=num_words,\n",
        "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "               lower=True,\n",
        "               split=\" \")\n",
        "#Complete data is tokenized to vectors and padding is done using zeros to match its length to the largest text in the dataset.\n",
        "tk.fit_on_texts(X)\n",
        "X = tk.texts_to_sequences(X)\n",
        "X = pad_sequences(X)\n",
        "#print(X[:2])\n",
        "print('Fitted tokenizer on {} documents'.format(tk.document_count))\n",
        "print('{} words in dictionary'.format(tk.num_words))\n",
        "print('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(5))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitted tokenizer on 11541 documents\n",
            "15000 words in dictionary\n",
            "Top 5 most common words are: [('united', 3426), ('flight', 3321), ('usairways', 2651), ('americanair', 2465), (\"n't\", 1878)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "GF8DK2-1Y3CA",
        "outputId": "8cea57eb-176e-4da0-af73-f3779fd6b931"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(tk,open('transform2.pkl','wb'))\n",
        "files.download('transform2.pkl')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0ae223c2-88c0-4152-8d4f-4476456fb097\", \"transform2.pkl\", 581861)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CeCPtjnUWIl",
        "outputId": "2c2cf6bd-7027-40c6-9b18-f494cc65eba3"
      },
      "source": [
        "#train test split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
        "print('# Train data samples:', X_train.shape)\n",
        "print('# Test data samples:', X_test.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Train data samples: (9232, 27)\n",
            "# Test data samples: (2309, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hndF1pitCISi",
        "outputId": "5aba6b0b-7180-49c5-c89d-64dd5b68b637"
      },
      "source": [
        "#getting validation data as a part of training data\n",
        "X_train_rest, X_valid, Y_train_rest, Y_valid = train_test_split(X_train,Y_train, test_size=0.1, random_state=37)\n",
        "print('Shape of validation set:',X_valid.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of validation set: (924, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnlWWTk-E4D4"
      },
      "source": [
        "#Function defined to test the models in the test set\n",
        "def test_model(model, epoch_stop):\n",
        "    model.fit(X_test\n",
        "              , Y_test\n",
        "              , epochs=epoch_stop\n",
        "              , batch_size=batch_size\n",
        "              , verbose=0)\n",
        "    results = model.evaluate(X_test, Y_test)\n",
        "    \n",
        "    return results"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1kMJUhJOnDL",
        "outputId": "7db5949c-b11e-4ce4-843c-b2b7c18d7c58"
      },
      "source": [
        "embed_dim = 128 #dimension of the word embedding vector for each word in a sequence \n",
        "lstm_out = 196  #no of lstm layers\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(num_words, embed_dim,input_length = X_train.shape[1]))\n",
        "#Adding dropout\n",
        "lstm_model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "#Adding a regularized dense layer\n",
        "lstm_model.add(layers.Dense(32,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
        "lstm_model.add(layers.Dropout(0.5))\n",
        "lstm_model.add(Dense(2,activation='softmax'))\n",
        "lstm_model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(lstm_model.summary())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 27, 128)           1920000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                6304      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 2,181,170\n",
            "Trainable params: 2,181,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnaNvVukOnIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63acbf00-f1c3-4476-fa39-b2437623e74f"
      },
      "source": [
        "#model trained on the training data and taking validation data into account to avoid overfitting for 4 epochs \n",
        "history_LSTM=lstm_model.fit(X_train_rest, Y_train_rest, epochs = 4, batch_size=batch_size,validation_data=(X_valid, Y_valid),verbose = 1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "17/17 [==============================] - 17s 839ms/step - loss: 0.6674 - accuracy: 0.7378 - val_loss: 0.5032 - val_accuracy: 0.7955\n",
            "Epoch 2/4\n",
            "17/17 [==============================] - 13s 790ms/step - loss: 0.4765 - accuracy: 0.7948 - val_loss: 0.3673 - val_accuracy: 0.8377\n",
            "Epoch 3/4\n",
            "17/17 [==============================] - 13s 789ms/step - loss: 0.3347 - accuracy: 0.8740 - val_loss: 0.2944 - val_accuracy: 0.8983\n",
            "Epoch 4/4\n",
            "17/17 [==============================] - 13s 782ms/step - loss: 0.2267 - accuracy: 0.9429 - val_loss: 0.2332 - val_accuracy: 0.9199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgOA7WOIeQSZ",
        "outputId": "78ea1d40-2847-4860-d5e5-39514a6e2ce9"
      },
      "source": [
        "#prediction by our lstm model on the test dataset\n",
        "lstm_results = test_model(lstm_model, 3)\n",
        "print('/n')\n",
        "print('Test accuracy of lstm model: {0:.2f}%'.format(lstm_results[1]*100))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73/73 [==============================] - 1s 19ms/step - loss: 0.1329 - accuracy: 0.9636\n",
            "/n\n",
            "Test accuracy of lstm model: 96.36%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9E-WBbZcYUfz",
        "outputId": "9ad75f61-49f1-45cc-ebc9-6b17b03e24d3"
      },
      "source": [
        "lstm_model.save('lstm_model.h5')\n",
        "from google.colab import files\n",
        "files.download('lstm_model.h5')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2296e196-ae0b-47e9-b8d1-feec6df06ac4\", \"lstm_model.h5\", 26215928)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D48NAU0nXEcR"
      },
      "source": [
        "#building the model using Keras Tuner so taking a range of values for the layers desired to be tuned.\n",
        "def build_model(hp):  \n",
        "  tuned_lstm_model = keras.Sequential([     \n",
        "     # giving range of values for output_dim for tuning for Embedding layer                                  \n",
        "     keras.layers.Embedding(\n",
        "        input_dim=num_words, \n",
        "        output_dim=hp.Int('embeddings', min_value=32, max_value=128, step=16),\n",
        "        input_length = X_train.shape[1]\n",
        "    ),      \n",
        "      # giving range of values for no. of units for tuning for LSTM layer\n",
        "      keras.layers.LSTM(\n",
        "        units=hp.Int('lstm_1_units', min_value=64, max_value=224,step=32), \n",
        "        dropout=hp.Int('drop_1_units', min_value=0, max_value=8,step=2)/10,\n",
        "        recurrent_dropout=0.0\n",
        "    ),                                                  \n",
        "    # giving range of values for no. of units for tuning for dense layer\n",
        "    keras.layers.Dense(\n",
        "        units=hp.Int('dense_2_units', min_value=32, max_value=128, step=16),\n",
        "        activation='relu',\n",
        "        kernel_regularizer=regularizers.l2(0.001)\n",
        "    ),   \n",
        "    # giving range of values for rate for tuning for dropout layer\n",
        "    keras.layers.Dropout(\n",
        "        rate=hp.Int('drop_1_rate', min_value=1, max_value=8, step=1)/10), \n",
        "    keras.layers.Dense(2, activation='softmax')\n",
        "  ])\n",
        "  #model compiled using Adam's optimizer with choices for learning rate\n",
        "  tuned_lstm_model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return tuned_lstm_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww9khaEBYfK9"
      },
      "source": [
        "#A function defined for keras tuner to look at each of the models\n",
        "tuner_search=RandomSearch(build_model,\n",
        "                          objective='val_accuracy',\n",
        "                          max_trials=5,directory='dir',\n",
        "    project_name='lstm_sentiment_Analysis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvETFy5PYfP1",
        "outputId": "1d718a1d-dcc2-48b9-97c4-a1fc6eb251da"
      },
      "source": [
        "#function called to search the results for different combinations of the parameter values in layers\n",
        "tuner_search.search(X_train_rest,Y_train_rest,epochs=3,validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 00m 37s]\n",
            "val_accuracy: 0.9329004287719727\n",
            "\n",
            "Best val_accuracy So Far: 0.9372294545173645\n",
            "Total elapsed time: 00h 03m 27s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6YWjAFGYfRh",
        "outputId": "547730fa-d269-44ca-87f5-d650073319a9"
      },
      "source": [
        "#to get the best model parameters\n",
        "tuned_lstm_model=tuner_search.get_best_models(num_models=1)[0]\n",
        "tuned_lstm_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 27, 48)            720000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 160)               133760    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 96)                15456     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 194       \n",
            "=================================================================\n",
            "Total params: 869,410\n",
            "Trainable params: 869,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m_m1UbQdXTt",
        "outputId": "d3339b72-8050-491c-b711-cd5df61115f0"
      },
      "source": [
        "#model trained on the training data and taking validation data into account to avoid overfitting for 4 epochs \n",
        "history_LSTM=lstm_model.fit(X_train_rest, Y_train_rest, epochs = 4, batch_size=batch_size,validation_data=(X_valid, Y_valid),verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "17/17 [==============================] - 12s 701ms/step - loss: 0.1209 - accuracy: 0.9693 - val_loss: 0.2269 - val_accuracy: 0.9242\n",
            "Epoch 2/4\n",
            "17/17 [==============================] - 12s 694ms/step - loss: 0.1000 - accuracy: 0.9763 - val_loss: 0.2243 - val_accuracy: 0.9264\n",
            "Epoch 3/4\n",
            "17/17 [==============================] - 12s 702ms/step - loss: 0.0713 - accuracy: 0.9863 - val_loss: 0.2507 - val_accuracy: 0.9264\n",
            "Epoch 4/4\n",
            "17/17 [==============================] - 12s 690ms/step - loss: 0.0548 - accuracy: 0.9901 - val_loss: 0.3078 - val_accuracy: 0.9351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed-W3dZ4dBd3",
        "outputId": "81b3d1e0-e7ad-4ca2-ff87-587b67a56301"
      },
      "source": [
        "#prediction by our tuned lstm model on the test dataset. This accuracy is better than the untuned model\n",
        "lstm_results = test_model(tuned_lstm_model, 5)\n",
        "print('/n')\n",
        "print('Test accuracy of lstm model: {0:.2f}%'.format(lstm_results[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73/73 [==============================] - 1s 14ms/step - loss: 0.0694 - accuracy: 0.9809\n",
            "/n\n",
            "Test accuracy of lstm model: 98.09%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk26OATDiXXv"
      },
      "source": [
        "##Now we will see the predictions by our model on sample movie reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGinF3USilsL"
      },
      "source": [
        "***Class 1 is positive class and class 0 is negative class***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQwynIG4HyeL",
        "outputId": "7470dae9-9522-43c3-fe15-b0e695ef3056"
      },
      "source": [
        "#First the sample text is a positive review, so lets see its prediction by our model\n",
        "sample_text = ('The service was good. Everything was so awesome. Highly recommended.')\n",
        "#converting into sequence because my model is trained on such a sequence\n",
        "sample = tk.texts_to_sequences([sample_text])\n",
        "sample = pad_sequences(sample)\n",
        "sample.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbjpJ6yCZ5mu",
        "outputId": "b33d3d8d-e895-4c7c-b5a5-95ed0cde7f16"
      },
      "source": [
        "#In training 27 was the no of tokens for each tweet so padding by zeros so that model can accept it\n",
        "k=np.zeros((1,27))\n",
        "k[0,-sample.shape[1]:]=sample\n",
        "k"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
              "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., 2423.,\n",
              "          14., 7534.,   89.,  456., 7534., 2175.,  190., 2243., 3829.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8MIEpNnHygz",
        "outputId": "da98b64f-c1fb-426c-d0a4-aa4a1492377a"
      },
      "source": [
        "#Prediction by model and as expected we get the class as 1 by almost 83%\n",
        "predictions = lstm_model.predict_classes(np.array(k))\n",
        "prediction_probability=lstm_model.predict(np.array(k))\n",
        "print(predictions)\n",
        "print(prediction_probability[0])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "[0.06591979 0.9340802 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiqGImrlevsV",
        "outputId": "e6e66147-7b48-4034-e995-0762a2cb2240"
      },
      "source": [
        "#Prediction by tuned model and as expected we get the class as 1 by almost 95%\n",
        "predictions = tuned_lstm_model.predict_classes(np.array(k))\n",
        "prediction_probability=tuned_lstm_model.predict(np.array(k))\n",
        "print(predictions)\n",
        "print(prediction_probability[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "[0.04985565 0.95014435]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRO6SxWxQ8l3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a00608-08cc-4be8-9a1f-df83e8f9b13e"
      },
      "source": [
        "#Secondly the sample text is a negative review, so lets see its prediction by our model\n",
        "sample_text = ('The movie was pathetic and terrible.Nothing was making any sense. Highly unacceptable.')\n",
        "#converting into sequence because my model is trained on such a sequence\n",
        "sample = tk.texts_to_sequences([sample_text])\n",
        "sample = pad_sequences(sample)\n",
        "sample.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M84WOeQOS4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa78d400-6b2c-4f01-976d-0865b0c059db"
      },
      "source": [
        "#In training 27 was the no of tokens for each tweet so padding by zeros so that model can accept it\n",
        "k=np.zeros((1,27))\n",
        "k[0,-13:]=sample\n",
        "k"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "            0.,     0.,     0.,     0.,     0.,     0.,  2423.,  1348.,\n",
              "         7534.,   845.,  1778.,   223.,   153.,  7534.,   228., 12070.,\n",
              "          656.,  2243.,   257.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddzv2kjfj-kf",
        "outputId": "32556f59-e68d-45c9-d903-e5f9332fd1f9"
      },
      "source": [
        "#Prediction by model and as expected we get the class as 0 by 99.99% probability. \n",
        "predictions = lstm_model.predict_classes(np.array(k))\n",
        "prediction_probability=lstm_model.predict(np.array(k))\n",
        "print(predictions)\n",
        "print(prediction_probability[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[9.9999213e-01 7.8319226e-06]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGejIeFyfDuK",
        "outputId": "7c7b7b87-eafb-4320-a9df-2b17d60e172d"
      },
      "source": [
        "#Prediction by tuned model and as expected we get the class as 0 by 99.99% probability. \n",
        "predictions = tuned_lstm_model.predict_classes(np.array(k))\n",
        "prediction_probability=tuned_lstm_model.predict(np.array(k))\n",
        "print(predictions)\n",
        "print(prediction_probability[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[9.999629e-01 3.712654e-05]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}